################################ 
# -- TRAIN -- 
################################
dataset_original_dir: data/woodscape/

dataset_dir: synthetic_shapes #data/gen_woodscape_u_resized/
# train_file: data/gen_woodscape_u_resized/train.txt
# val_file: data/gen_woodscape_u_resized/val.txt
# test_file: data/gen_woodscape_u_resized/test.txt

load_edges: False                     # Load Canny edge image
#loader: fast
do_resize: True
do_polar_mapping: True
input_height: 400                    # network input height choose from the above options
input_width: 400                     # network input width choose from the above options
polar_width: 400
output_directory: output/synthetic_shapes/ # Path to save images, model weights of training
synth_config: code/calib/configs/magic-point_shapes.yaml
task: det
kernel_size: 3

################################
# -- MODEL CONFIGS --
################################
# choices:                      [fconv_adaptive_polar, fconv_gap_polar, 
#                                 resize_gap_polar, resize_gap_polar_huber, resize_gap_polar_mae,
#                                 resize_2step_polar]
# detection:                    [detection_base]



model_name: detection_v3          # Writers will be written based on the model name
description: Base detector trained on syntethic shapes


################################
# -- NETWORK --
################################
network_fe_layers: 3              # Number of layers of the feature extractor
network_fc_layers: 3              # Number of layers of the fully connected head

#############################
# -- TRAIN OPTIONS --
#############################
batch_size: 32                # training size of the model
num_workers: 4                # Data loader workers
epochs: 100                    # number of epochs
learning_rate: 0.0001         # learning rate of the model
scheduler_patience: 10
scheduler_factor: 0.5
scheduler_min_lr : 1e-5

  ### -- Early stopping --
do_early_stopping: True
patience : 10                  # Number of epochs to wait for a better value
min_delta : 1e-5              # Slight differences in validation loss are not considered significant
starting_epoch : 10           # Epoch that defines the start of Early stopping.

  ### -- LOSSES --
reference_train_metric: det_loss
reference_val_metric: det_loss_val
loss_huber_delta: 0.3

################
# -- WEIGHTS --
################
train_va_weights: False
test_va_weights: False

#############################
# -- LOGGING OPTIONS --
#############################
log_frequency: 10            # number of batches between each tensorboard log

#############################
# -- TEST OPTIONS --
#############################
# Path to save tensorboard events. If empty is the same as pretrained weights.
test_suff:
test_save_rectified_imgs: False
test_save_calibration_params: False
test_visualize_batch_details: True
test_metrics_df_path: # 'benchmark/calibration/gen_woodscape_u_resized/metrics/evaluation.csv' # Path to the dataframe containing the metrics. If it does not exist it is created.
test_img_out_path: 'benchmark/calibration/gen_woodscape_u_resized/images/'
test_param_out_path: 'benchmark/calibration/gen_woodscape_u_resized/params/'
test_img_out_height: 300
test_img_out_width: 300

###########################
# -- PRE_TRAINED CONFIG --
###########################
# Pre-trained weights folder path of trained models to resume training and for testing
pretrained_weights:  # 'output/gen_woodscape_u_resized/resize_gap_polar_2023-02-09_01-47-34'
epoch_to_load:               # Number of the epoch to load if multiple options are availble. Empty is the last epoch
models_to_load: ["net"]
freeze_encoder: True
optimizer:

####################################################
# -- CUDA --
#############################
device: 'cuda:0'             # choose cpu or cuda:0 device
cuda_visible_devices: "0"    # To forcefully run the model on CPU set -1 else set string value to 0
use_multiple_gpu: False      # Data parallelism
########################################################################################################################
